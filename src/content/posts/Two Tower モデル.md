---
title: TwoTowerモデル in Recall
date: 2025-06-19
lastMod: 2025-06-19T18:49:00.000Z
tags: [Machine Learning, Recommendation, Recall]
category: 推薦システム
summary: Two Towerモデルを紹介します。
---

# TL;DR

## What

ユーザーとアイテムをそれぞれ独立したタワーでエンコードし、内積でマッチ度を計算する推薦手法。リコール段階で一番使われる手法。

## Why

- 学習を通じて**embedding**を獲得することで、ユーザーとアイテムの多次元な特徴属性を十分に活用することができる。

- ユーザーとアイテムは完全に**分離**されており、内積形式でモデル化されているため、近似最近傍（ANN）による高速化が可能

- アイテムタワーはユーザー情報に一切依存しないため、膨大なアイテムの埋め込みを周期的・バッチ処理・オフラインで生成することができ、オンラインのサービング負荷を大幅に軽減できる

## How

![](https://github.com/minasora/picx-images-hosting/raw/master/image.esru6k9mf.webp)

# Two TowerのInput

推薦システムに存在している特徴：

User側：ユーザーID,ユーザーの離散特徴量、ユーザーの連続特徴量

Item側：アイテムID,アイテムの離散特徴量、アイテムの連続特徴量

**ID** → Embedding Layer

**ユーザーの離散特徴量** → Embedding Layer

**ユーザーの連続特徴量** → 正規化 / ビン分割（分桶）→　Embedding Layer

![](https://github.com/minasora/picx-images-hosting/raw/master/image.361u2ahk1u.png)

# Two Towerアーキテクチャ

簡単ならMLP →　複雑なら Attentionなど あります。

ここが割愛、後もまとめしたいですが、ここにYoutubeのアーキテクチャ貼っています。
![](https://github.com/minasora/picx-images-hosting/raw/master/image.64e45rjoaa.webp)

# Two Towerのトレーニング

## 正例・負例 in Two Tower

Two Tower モデルでは、ユーザーとアイテムをそれぞれ独立したエンコーダ（タワー）でベクトル（embedding）に変換し、ユーザーがどのアイテムに興味を持つかを、これらのベクトルの内積（類似度）で予測します。

このとき重要なのが「**正例**」と「**負例**」の設定です。

- **正例（ポジティブサンプル）**：ユーザーが実際にクリック・購入などの行動を取ったアイテム。ユーザーの興味があるとみなされる。
- **負例（ネガティブサンプル）**：ユーザーが行動しなかった、または興味がないとみなされるアイテム。

![](https://github.com/minasora/picx-images-hosting/raw/master/image.60ui81sn6i.webp)

## Two Towerの損失関数

主に3つの損失関数があります。Solutionによる性能も異なります。

### Pointwise Learning

#### **What**

正例・負例をそれぞれ独立に扱い、二値分類として学習を行う。

#### **How**

- 正例サンプルに対しては、$cos(a, b)$ が +1 に近づくように促す。
- 負例サンプルに対しては、$cos(a, b)$ が -1 に近づくように促す。
- 正例と負例のサンプル数の比率は 1:2 または 1:3 に調整する。

### Pairwise Learning

![](https://github.com/minasora/picx-images-hosting/raw/master/屏幕截图-2025-06-19-215157.9kgfxx41bq.webp)

#### **What**

毎回、1つの正例 $b⁺$と1つの負例 $b⁻$をペアで取り出し、どちらのスコアが高いべきかを学習する。

#### **How**

基本的な考え方：cos(a, b⁺)が$cos(a, b⁻)$ より大きくなるように促す

- $cos(a, b⁺)$が $cos(a, b⁻)$ $+ m$ より大きければ，損失は0
- そうでなければ，損失は $cos(a, b⁻) + m − cos(a, b⁺)$

$$L(a, b^+, b^-) = \max\!\bigl\{0,\;\cos(a, b^-) + m - \cos(a, b^+)\bigr\}$$

### ListWise Learning

#### **What**

毎回、1つの正例と複数の負例をまとめて取り出し、リストして学習する。

#### **How**

1つのデータには以下が含まれる：

- 1人のユーザー（特徴ベクトルをa とする）
- 1つの正例（特徴ベクトルを b⁺ とする）
- 複数の負例（特徴ベクトルをb₁⁻, …, bₙ⁻ とする）

目標としては

- cos(a, b⁺)をできるだけ大きくするように促す。
- cos(a, b₁⁻) から cos(a, bₙ⁻) をできるだけ小さくするように促す。

![](https://github.com/minasora/picx-images-hosting/raw/master/屏幕截图-2025-06-19-214027.7axfef4zxr.webp)

# Two TowerのServing

推論フェーズでは、以下の手順で動作します。

1. 学習が完了した後、アイテムタワーを使って各アイテムの特徴ベクトルを計算する；

2. 数億件のアイテムベクトルをベクトルデータベースに保存する；

3. ベクトルデータベースにインデックスを構築し、近傍検索の高速化を図る。

その後、オンラインでユーザーが最も関心を持ちそうなアイテムをリコールします：

ユーザーIDとユーザープロファイル（ユーザーの多次元特徴）をもとに、オンラインでユーザータワーによってユーザーベクトルを計算；

近傍検索を実行：

1. このユーザーベクトルをクエリベクトルとして、ベクトルデータベースに問い合わせ；

2. コサイン類似度が最も高いアイテムをK件取得し、リコール結果として返す。

ここで、事前にアイテムベクトルを計算・保存し、オンラインではユーザーベクトルのみを計算する理由は以下の通りです：

1. 毎回のリコールで使用されるユーザーベクトルは1つのみであるのに対し、アイテムベクトルは数億件にのぼるため、オンラインで全てのアイテムベクトルを計算するのは非常にコストが高い。

2. ユーザーの興味は動的に変化するのに対し、アイテムの特徴は比較的安定している。そのため、ユーザーベクトルをオフラインで保存することも可能ではあるが、リアルタイム性のある推薦には向かない。

# Two Towerの性能向上

## 自己教師あり学習

### What

Unlabeled Data を利用してモデルの性能向上させる
元の論文：[https://arxiv.org/abs/2007.12865]()

### Why

Two Tower Modelに基づくレコメンデーションシステムには、深刻なヘッドコンテンツバイアスが存在します。つまり、ごく一部のアイテムが大部分のクリック数を占めており、大多数のアイテムはクリック数が少ないため、レコメンデーションシステムはクリック数の多いアイテムの表現はよく学習できても、ロングテールアイテムの学習は困難です。

そこで、**自己教師あり学習**を取り入れ、データ拡張（data augmentation）を行うことで、ロングテールアイテムの表現をより適切に学習できるようになります。

### How

1. 希望するアイテム i の2つのベクトル表現 $b_i^{'}​$ と $b_i^{''}$​の類似度が高くなるように促し、 $\cos(b_i', b_i'')$ をできるだけ大きくする；

2. 希望するアイテムiと別のアイテムjのいずれかのベクトル表現（例えば $b_i'$ と $b_j''​$）が低い類似度を持つように促し、$\cos(b_i', b_j'')$をできるだけ小さくする。

![](https://github.com/minasora/picx-images-hosting/raw/master/屏幕截图-2025-06-19-205742.491jd5kak9.webp)

#### 特徴変換

いろいろ変換ありますけど、ここに最も使われる二つ紹介いたします。

**Random Mask**：特徴の一部をランダムに選択してマスク（未知値／デフォルト値に置換）する
**Dropout**：ある特徴に対し、要素の50%をランダムにゼロ（またはデフォルト値）に置換する
